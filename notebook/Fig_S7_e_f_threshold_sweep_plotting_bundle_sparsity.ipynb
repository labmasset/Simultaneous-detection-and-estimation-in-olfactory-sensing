{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib h5py scipy seaborn scikit-learn --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544cd03-8dac-4ef8-b750-c675dc178649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent \n",
    "# sys.path.append(str(project_##root))\n",
    "\n",
    "BASE_DIR = Path.cwd().parent  # go up one level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db82e4-bd88-4789-80a7-01eafe7be1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from matplotlib.colors import Normalize\n",
    "# Import the analysis module\n",
    "from mirrored_langevin_rnn.utils.data_pipeline.threshold_sweep_analysis import (\n",
    "    load_threshold_batch_files,\n",
    "    plot_threshold_heatmap,\n",
    "    merge_threshold_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddf70c",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the experiment configuration, including file patterns and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a3b45-a037-46fd-824a-0ef801fb700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisson_out_dirs = [\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"poisson\" / \"l1\" / \"affinity_dense_gamma\",\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"poisson\" / \"l1\" / \"affinity_sparse_gamma_sparsity_0.10\",\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"poisson\" / \"l1\" / \"affinity_sparse_binary_sparsity_0.10\",\n",
    "# ]\n",
    "# slam_ber_out_dirs = [\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"l1\" / \"bernoulli\" / \"affinity_dense_gamma\",\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"l1\" / \"bernoulli\" / \"affinity_sparse_gamma_sparsity_0.10\",\n",
    "#     BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"l1\" / \"bernoulli\" / \"affinity_sparse_binary_sparsity_0.10\",\n",
    "# ]\n",
    "slam_kum_out_dirs = [\n",
    "    BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"auc\" / \"kumaraswamy\" / \"affinity_sparse_binary_sparsity_0.10\",\n",
    "    BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"auc\" / \"kumaraswamy\" / \"affinity_sparse_binary_sparsity_0.20\",\n",
    "    BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"auc\" / \"kumaraswamy\" / \"affinity_sparse_binary_sparsity_0.30\",\n",
    "    BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"auc\" / \"kumaraswamy\" / \"affinity_sparse_binary_sparsity_0.40\",\n",
    "    BASE_DIR / \"data\" / \"threshold_sweep\" / \"slam\" / \"auc\" / \"kumaraswamy\" / \"affinity_sparse_binary_sparsity_0.50\",\n",
    "]\n",
    "\n",
    "plot_combination = [\n",
    "    # (\"poisson_l1_binary_threshold_results_batch*.h5\", poisson_out_dirs),\n",
    "    # (\"slam_l1_bernoulli_threshold_results_batch*.h5\", slam_ber_out_dirs),\n",
    "    (\"slam_auc_kumaraswamy_threshold_results_batch*.h5\", slam_kum_out_dirs),\n",
    "]\n",
    "\n",
    "# FILE_PATTERN = \"slam_auc_bernoulli_threshold_results_batch*.h5\"\n",
    "# FILE_PATTERN = \"slam_auc_kumaraswamy_threshold_results_batch*.h5\"\n",
    "# FILE_PATTERN = \"poisson_rank_binary_threshold_results_batch*.h5\"\n",
    "# FILE_PATTERN = \"poisson_rank_threshold_results_batch*.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_label = True\n",
    "# Save SVG to the figures directory\n",
    "figures_dir = BASE_DIR / \"figures\" / \"threshold_sweep\" / \"sparsity\" / \"auc\"\n",
    "if hide_label:\n",
    "    figures_dir = figures_dir / \"labels_hidden\"\n",
    "else:\n",
    "    figures_dir = figures_dir / \"labels_visible\"\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3b4a2-3a8e-4d6c-8a1f-8a7b3b5d7a3c",
   "metadata": {},
   "source": [
    "## Visualize the Merged Threshold Sweep Results\n",
    "\n",
    "Now we'll create a heatmap visualization of the merged grid with contour lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygments import highlight\n",
    "\n",
    "selected_positions = [\n",
    "    (2095, 450),  # Very high odors, high sensors\n",
    "    (3031, 450),  # Maximum odors, maximum sensors\n",
    "    (4387, 450),   # High odors, high sensors\n",
    "]\n",
    "\n",
    "colors = ['#FFB000', '#FE6100', '#DC267F']\n",
    "#  '#d62728', '#9467bd'\n",
    "\n",
    "def create_threshold_heatmap_plot(out_dir, file_pattern, plot_title=None, hide_axis_labels=True):\n",
    "    \"\"\"\n",
    "    Create a threshold heatmap plot for given output directory and file pattern.\n",
    "    \n",
    "    Args:\n",
    "        out_dir: Path to output directory containing batch files\n",
    "        file_pattern: File pattern to match batch files\n",
    "        n_odor_values: Number of odor values for grid\n",
    "        n_sens_values: Number of sensor values for grid\n",
    "        plot_title: Optional title for the plot\n",
    "        hide_axis_labels: Whether to hide axis labels (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (fig, ax, merged_grid, merged_path)\n",
    "    \"\"\"\n",
    "    separatedColor = \"#D95319\"           # SLAM\n",
    "    circuitColor = \"#E13960\"\n",
    "    highlight_color = circuitColor\n",
    "    \n",
    "    grids, files, n_sens_values, n_odor_values = load_threshold_batch_files(\n",
    "        out_dir,\n",
    "        pattern=file_pattern\n",
    "    )\n",
    "    print(n_odor_values)\n",
    "    print(n_sens_values)\n",
    "    \n",
    "    # Merge the grids into a complete grid using the first valid value at each position\n",
    "    merged_grid, merged_path = merge_threshold_batches(\n",
    "        out_dir, \n",
    "        pattern=file_pattern,\n",
    "        output_file=\"threshold_results_merged.h5\",\n",
    "        merge_method=\"first_valid\"  # Use first valid value (alternatives: \"max\", \"min\", \"mean\")\n",
    "    )\n",
    "\n",
    "    print(f\"Processing: {out_dir}\")\n",
    "    print(f\"Pattern: {file_pattern}\")\n",
    "    print(f\"Merged grid shape: {merged_grid.shape}\")\n",
    "    print(f\"Saved to: {merged_path}\")\n",
    "\n",
    "    # Count non-NaN values to check grid completeness\n",
    "    non_nan_count = np.count_nonzero(~np.isnan(merged_grid))\n",
    "    total_cells = merged_grid.size\n",
    "    print(f\"Grid completeness: {non_nan_count}/{total_cells} cells filled ({non_nan_count/total_cells:.1%})\")\n",
    "\n",
    "    # Create a figure and plot the heatmap\n",
    "    fig, ax = plot_threshold_heatmap(\n",
    "        merged_grid,\n",
    "        n_odor_values,\n",
    "        n_sens_values,\n",
    "        figsize=(7,6),\n",
    "        cmap=\"Blues\",\n",
    "        sigma=2,  # Gaussian smoothing parameter\n",
    "        contour_levels = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        highlight_level=50,\n",
    "        annot=False,\n",
    "        highlight_color=highlight_color  # Use the provided highlight color\n",
    "    )\n",
    "    ax.set_xlim([1000, 16000])\n",
    "    \n",
    "    # Add dots at selected positions\n",
    "    for (odor_val, sens_val), color in zip(selected_positions, colors):\n",
    "        ax.plot(odor_val, sens_val, 'o', color=color, markersize=16)\n",
    "    \n",
    "    # Configure colorbar\n",
    "    norm = Normalize(vmin=5, vmax=100)\n",
    "    cbar = fig.colorbar(ax.collections[0], ax=ax, shrink=0.9, aspect=9)\n",
    "    cbar.mappable.set_norm(norm)\n",
    "    cbar.set_ticks([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "    cbar.ax.tick_params(width=0)\n",
    "    cbar.set_ticklabels([\"\", '20', \"\", '40', \"\", '60', \"\", '80', \"\", '100+'], fontsize=16)\n",
    "    cbar.outline.set_linewidth(2)\n",
    "    \n",
    "    # Add contour lines to colorbar\n",
    "    contour_levels = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    for level in contour_levels:\n",
    "        if level == 50:\n",
    "            cbar.ax.axhline(level, xmin=0.66, xmax=1, color=highlight_color, linestyle='solid', linewidth=3)\n",
    "        else:\n",
    "            cbar.ax.axhline(level, xmin=0.66, xmax=1, color='black', linestyle='solid', linewidth=2)\n",
    "    \n",
    "    cbar.ax.set_visible(not hide_axis_labels)\n",
    "    \n",
    "    # Apply hide_labels if requested\n",
    "    if hide_axis_labels:\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)\n",
    "        cbar.ax.set_visible(False)\n",
    "    \n",
    "    return fig, ax, merged_grid, merged_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e0963",
   "metadata": {},
   "source": [
    "## Generate All Threshold Heatmap Plots\n",
    "\n",
    "The following code will automatically generate threshold heatmap plots for all combinations defined in `plot_combination`. This includes:\n",
    "\n",
    "- **3 Poisson model configurations**: dense gamma, sparse binary, sparse gamma\n",
    "- **3 SLAM Bernoulli configurations**: dense gamma, sparse gamma, sparse binary  \n",
    "- **3 SLAM Kumaraswamy configurations**: dense gamma, sparse binary, sparse gamma\n",
    "\n",
    "Each plot will be saved with a descriptive filename and displayed in the notebook. The function `create_threshold_heatmap_plot()` handles the data loading, merging, visualization, and colorbar configuration for each combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ba48c-6ace-47a7-a27d-d8ffe320f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots for all combinations\n",
    "plot_results = []\n",
    "\n",
    "for file_pattern, out_dirs in plot_combination:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing file pattern: {file_pattern}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, out_dir in enumerate(out_dirs):\n",
    "        # Use out_dir as the title\n",
    "        plot_title = str(out_dir)\n",
    "        out_dir = Path(out_dir) \n",
    "        fig, ax, merged_grid, merged_path = create_threshold_heatmap_plot(\n",
    "            out_dir, \n",
    "            file_pattern, \n",
    "            plot_title=plot_title,\n",
    "            hide_axis_labels=hide_label \n",
    "        )\n",
    "        \n",
    "        # Create filename based on directory structure\n",
    "        dir_parts = str(out_dir).split('/')\n",
    "        plot_filename_base = f\"threshold_heatmap_{file_pattern.replace('*', '').replace('.h5', '')}_{dir_parts[-1]}\"\n",
    "        \n",
    "        # Save PNG to the output directory\n",
    "        # plt.savefig(out_dir / f\"{plot_filename_base}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.savefig(figures_dir / f\"{plot_filename_base}.svg\", bbox_inches=\"tight\")\n",
    "        \n",
    "        # Store results for later analysis if needed\n",
    "        plot_results.append({\n",
    "            'out_dir': out_dir,\n",
    "            'file_pattern': file_pattern,\n",
    "            'plot_title': plot_title,\n",
    "            'merged_grid': merged_grid,\n",
    "            'merged_path': merged_path,\n",
    "            'plot_filename': plot_filename_base\n",
    "        })\n",
    "        \n",
    "        plt.show()\n",
    "        print(f\"\\nCompleted {i+1}/{len(out_dirs)} for pattern {file_pattern}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"All plots completed! Generated {len(plot_results)} plots total.\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78a809",
   "metadata": {},
   "source": [
    "## Maximum Capacity vs. Sparsity Analysis\n",
    "\n",
    "Analyze maximum capacity values for specific grid cells (n_odors, n_sensors combinations) across different sparsity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameter grid\n",
    "start = 1000\n",
    "end = 16000 \n",
    "num = 16\n",
    "x_axis = tuple(sorted({int(round(x)) for x in np.logspace(np.log10(start), np.log10(end), num)}))\n",
    "\n",
    "y_start = 100\n",
    "y_end = 800\n",
    "y_stepsize = 50\n",
    "y_axis = tuple(range(y_start, y_end + 1, y_stepsize))\n",
    "\n",
    "print(x_axis)\n",
    "print(y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_max_capacity_for_positions(base_dirs, file_pattern, positions, sparsity_values):\n",
    "    \"\"\"\n",
    "    Extract maximum capacity values for specific grid positions across different sparsity levels.\n",
    "    \n",
    "    Args:\n",
    "        base_dirs: List of directory paths for different sparsity levels\n",
    "        file_pattern: File pattern to match batch files\n",
    "        positions: List of (n_odors, n_sensors) tuples for grid positions to analyze\n",
    "        sparsity_values: List of sparsity values corresponding to base_dirs\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with position tuples as keys and max capacity arrays as values\n",
    "    \"\"\"\n",
    "    max_capacities = {pos: [] for pos in positions}\n",
    "    \n",
    "    for i, out_dir in enumerate(base_dirs):\n",
    "        print(f\"Processing sparsity {sparsity_values[i]}: {out_dir}\")\n",
    "        \n",
    "        try:\n",
    "            # Load and merge the grids for this sparsity level\n",
    "            grids, files, n_sens_values, n_odor_values = load_threshold_batch_files(\n",
    "                out_dir,\n",
    "                pattern=file_pattern\n",
    "            )\n",
    "            \n",
    "            print(f\"  Grid dimensions: n_odor_values={n_odor_values}, n_sens_values={n_sens_values}\")\n",
    "            \n",
    "            merged_grid, _ = merge_threshold_batches(\n",
    "                out_dir, \n",
    "                pattern=file_pattern,\n",
    "                output_file=f\"threshold_results_merged_sparsity_{sparsity_values[i]}.h5\",\n",
    "                merge_method=\"first_valid\"\n",
    "            )\n",
    "            \n",
    "            print(f\"  Merged grid shape: {merged_grid.shape}\")\n",
    "            print(f\"  Grid value range: {np.nanmin(merged_grid):.2f} to {np.nanmax(merged_grid):.2f}\")\n",
    "            \n",
    "            # Use the actual coordinate values directly (they are tuples, not counts)\n",
    "            n_odors_range = np.array(n_odor_values)\n",
    "            n_sensors_range = np.array(n_sens_values)\n",
    "            \n",
    "            print(f\"  n_odors range: {n_odors_range[0]} to {n_odors_range[-1]}\")\n",
    "            print(f\"  n_sensors range: {n_sensors_range[0]} to {n_sensors_range[-1]}\")\n",
    "            \n",
    "            # Extract values for each position\n",
    "            for pos in positions:\n",
    "                n_odors, n_sensors = pos\n",
    "                \n",
    "                # Find closest indices in the actual grid values\n",
    "                odor_idx = np.argmin(np.abs(n_odors_range - n_odors))\n",
    "                sens_idx = np.argmin(np.abs(n_sensors_range - n_sensors))\n",
    "                \n",
    "                # Get the actual coordinates\n",
    "                actual_n_odors = n_odors_range[odor_idx]\n",
    "                actual_n_sensors = n_sensors_range[sens_idx]\n",
    "                \n",
    "                max_capacity = merged_grid[odor_idx, sens_idx]\n",
    "                max_capacities[pos].append(max_capacity)\n",
    "                \n",
    "                print(f\"  Position ({n_odors}, {n_sensors}) -> grid[{odor_idx}, {sens_idx}] = \"\n",
    "                      f\"({actual_n_odors}, {actual_n_sensors}) = {max_capacity:.2f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {out_dir}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Fill with NaN for failed directories\n",
    "            for pos in positions:\n",
    "                max_capacities[pos].append(np.nan)\n",
    "    \n",
    "    return max_capacities\n",
    "\n",
    "# Define positions using exact values from the grid\n",
    "# Based on the actual grid values:\n",
    "# n_odors: (1000, 1203, 1447, 1741, 2095, 2520, 3031, 3647, 4387, 5278, 6350, 7639, 9190, 11055, 13300, 16000)\n",
    "# n_sensors: (100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800)\n",
    "# Grid shape is (15, 16), so odor index 0-14, sensor index 0-15\n",
    "selected_positions = [\n",
    "    (2095, 450),  # Very high odors, high sensors\n",
    "    (3031, 450),  # Maximum odors, maximum sensors\n",
    "    (4387, 450),   # High odors, high sensors\n",
    "]\n",
    "\n",
    "# Extract sparsity values from directory names\n",
    "sparsity_values = []\n",
    "for out_dir in slam_kum_out_dirs:\n",
    "    dir_str = str(out_dir)\n",
    "    if \"sparsity_0.10\" in dir_str:\n",
    "        sparsity_values.append(0.10)\n",
    "    elif \"sparsity_0.20\" in dir_str:\n",
    "        sparsity_values.append(0.20)\n",
    "    elif \"sparsity_0.30\" in dir_str:\n",
    "        sparsity_values.append(0.30)\n",
    "    elif \"sparsity_0.40\" in dir_str:\n",
    "        sparsity_values.append(0.40)\n",
    "    elif \"sparsity_0.50\" in dir_str:\n",
    "        sparsity_values.append(0.50)\n",
    "    else:\n",
    "        sparsity_values.append(0.0)  # default for dense\n",
    "\n",
    "print(\"Selected positions for analysis:\")\n",
    "for i, pos in enumerate(selected_positions):\n",
    "    print(f\"{i+1}. n_odors={pos[0]}, n_sensors={pos[1]}\")\n",
    "\n",
    "print(f\"\\nSparsity levels: {sparsity_values}\")\n",
    "\n",
    "# Extract the maximum capacity data\n",
    "max_capacity_data = extract_max_capacity_for_positions(\n",
    "    slam_kum_out_dirs, \n",
    "    \"slam_auc_kumaraswamy_threshold_results_batch*.h5\",\n",
    "    selected_positions,\n",
    "    sparsity_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirrored_langevin_rnn.utils.visualization.styling import apply_style\n",
    "\n",
    "\n",
    "def plot_max_capacity_vs_sparsity(max_capacity_data, sparsity_values, selected_positions, \n",
    "                                  figsize=(4, 3), save_path=None):\n",
    "    \"\"\"\n",
    "    Plot maximum capacity vs. sparsity for selected grid positions.\n",
    "    \n",
    "    Args:\n",
    "        max_capacity_data: Dictionary with position tuples as keys and capacity arrays as values\n",
    "        sparsity_values: List of sparsity values\n",
    "        selected_positions: List of (n_odors, n_sensors) tuples\n",
    "        figsize: Figure size tuple\n",
    "        save_path: Optional path to save the figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Define colors for different lines\n",
    "    # colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    # Plot each position as a separate line\n",
    "    for i, pos in enumerate(selected_positions):\n",
    "        capacities = np.array(max_capacity_data[pos])\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        valid_mask = ~np.isnan(capacities)\n",
    "        valid_sparsity = np.array(sparsity_values)[valid_mask]\n",
    "        valid_capacities = capacities[valid_mask]\n",
    "        \n",
    "        if len(valid_capacities) > 0:\n",
    "            ax.plot(valid_sparsity, valid_capacities, \n",
    "                   marker='o', linewidth=2.5, markersize=8,\n",
    "                   color=colors[i % len(colors)],\n",
    "                   label=f'({pos[0]}, {pos[1]})')\n",
    "    \n",
    "    # Customize the plot\n",
    "    # ax.set_xlabel('Sparsity Level', fontsize=14)\n",
    "    # ax.set_ylabel('Maximum Capacity', fontsize=14)\n",
    "    # ax.set_title('Maximum Capacity vs. Sparsity\\nfor Selected Grid Positions', fontsize=16, pad=20)\n",
    "    # ax.grid(True, alpha=0.3)\n",
    "    ax.legend(title='(n_odors, n_sensors)', fontsize=12, title_fontsize=12)\n",
    "    \n",
    "    apply_style(ax)\n",
    "    # Set axis limits and ticks\n",
    "    ax.set_xlim(0, max(sparsity_values) + 0.05)\n",
    "    ax.set_xticks(sparsity_values)\n",
    "    # ax.set_xticklabels([f'{s:.1f}' for s in sparsity_values])\n",
    "    ax.set_xticklabels([0.1, \"\", 0.3, \"\", 0.5])\n",
    "\n",
    "    \n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if path provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plot_max_capacity_vs_sparsity(\n",
    "    max_capacity_data, \n",
    "    sparsity_values, \n",
    "    selected_positions,\n",
    "    figsize=(4, 3),\n",
    "    save_path=figures_dir / \"max_capacity_vs_sparsity.svg\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for pos in selected_positions:\n",
    "    capacities = np.array(max_capacity_data[pos])\n",
    "    valid_capacities = capacities[~np.isnan(capacities)]\n",
    "    \n",
    "    if len(valid_capacities) > 0:\n",
    "        print(f\"Position {pos}:\")\n",
    "        print(f\"  Mean capacity: {np.mean(valid_capacities):.2f}\")\n",
    "        print(f\"  Min capacity: {np.min(valid_capacities):.2f}\")\n",
    "        print(f\"  Max capacity: {np.max(valid_capacities):.2f}\")\n",
    "        print(f\"  Std deviation: {np.std(valid_capacities):.2f}\")\n",
    "        \n",
    "        # Calculate trend (linear fit)\n",
    "        if len(valid_capacities) > 1:\n",
    "            valid_sparsity = np.array(sparsity_values)[~np.isnan(capacities)]\n",
    "            slope, intercept = np.polyfit(valid_sparsity, valid_capacities, 1)\n",
    "            print(f\"  Trend (slope): {slope:.2f} capacity/sparsity\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b141e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d1375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam-olfaction-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
